{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7b5c32-53e7-46a6-8fc1-c1a0f399d4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/kaggle-tweet-sentiment/.venv/lib64/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-01-30 01:24:47.295402: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738218287.306451  101502 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738218287.309823  101502 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-30 01:24:47.321036: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, losses, optimizers, metrics, regularizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ec501c-4145-4e78-ac9e-295391bde66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 23358 entries, 16039 to 5268\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         23358 non-null  object\n",
      " 1   text           23358 non-null  object\n",
      " 2   selected_text  23358 non-null  object\n",
      " 3   sentiment      23358 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 912.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4122 entries, 7068 to 18854\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         4122 non-null   object\n",
      " 1   text           4122 non-null   object\n",
      " 2   selected_text  4122 non-null   object\n",
      " 3   sentiment      4122 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 161.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\").dropna()\n",
    "train, test = train_test_split(train, test_size=0.15)\n",
    "print(train.info())\n",
    "print(test.info())\n",
    "# TODO see if selected_text needs to be fixed to word boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d49cf58-d62e-4887-b8dc-b120016513b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len = 128\n",
    "inference_batch_size = 2000\n",
    "\n",
    "def tokenize(texts, padding=True):\n",
    "    padding = \"max_length\" if padding else \"longest\"\n",
    "    return tokenizer(texts, padding=padding, max_length=max_text_len, return_tensors=\"tf\")\n",
    "\n",
    "def detokenize(ids, skip_special=True):\n",
    "    return tokenizer.batch_decode(ids, skip_special_tokens=skip_special)\n",
    "\n",
    "# https://stackoverflow.com/a/7100681\n",
    "def rolling_window(a, size):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - size + 1, size)\n",
    "    strides = a.strides + (a. strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "def find_span(texts, spans):\n",
    "    texts = np.array(texts)\n",
    "    spans = np.array(spans)[:, 1:]\n",
    "    sizes = spans.argmin(axis=1) - 1\n",
    "    span_ranges = np.zeros((texts.shape[0], 2))\n",
    "    for i, text in enumerate(texts):\n",
    "        window_size = sizes[i]\n",
    "        matched_window = rolling_window(texts[i], window_size) == spans[i][:window_size]\n",
    "        window_from = matched_window.all(axis=1).argmax()\n",
    "        span_ranges[i, 0] = window_from\n",
    "        span_ranges[i, 1] = window_from + window_size - 1\n",
    "    return span_ranges\n",
    "\n",
    "def eprint(*args, **kwargs):\n",
    "    print(*args, **kwargs, file=sys.stderr)\n",
    "\n",
    "def print_mem_info():\n",
    "    info = tf.config.experimental.get_memory_info(\"/gpu:0\")\n",
    "    eprint(f\"GPU memory usage {(info[\"current\"] / info[\"peak\"]):.2f}.\")\n",
    "\n",
    "def context_embeddings(texts, sentiments, selected_texts=None):\n",
    "    text_tokens = tokenize(texts)\n",
    "    text_embeddings = encoder(**text_tokens).last_hidden_state\n",
    "    sentiment_tokens = tokenize(sentiments)\n",
    "    sentiment_embeddings = encoder(**sentiment_tokens).last_hidden_state[:, 1:2, :]  # only need embedding for one word\n",
    "    embeddings = tf.concat((text_embeddings, sentiment_embeddings), 1)\n",
    "    if selected_texts is None:\n",
    "        return embeddings\n",
    "    else:\n",
    "        selected_tokens = tokenize(selected_texts)\n",
    "        targets = find_span(text_tokens[\"input_ids\"], selected_tokens[\"input_ids\"])\n",
    "        return embeddings, targets\n",
    "\n",
    "def dataset_generator(texts, sentiments, selected_texts=None):\n",
    "    def gen():\n",
    "        total = len(texts)\n",
    "        yielded = 0\n",
    "        while yielded < total:\n",
    "            batch_i = yielded % inference_batch_size\n",
    "            # batch inferencing\n",
    "            if batch_i == 0:\n",
    "                end = min(total, yielded + inference_batch_size)\n",
    "                if selected_texts is None:\n",
    "                    embeddings = context_embeddings(texts[yielded:end], sentiments[yielded:end])\n",
    "                else:\n",
    "                    embeddings, targets = context_embeddings(texts[yielded:end], sentiments[yielded:end], selected_texts[yielded:end])\n",
    "            # feed the generator\n",
    "            if selected_texts is None:\n",
    "                yield embeddings[batch_i]\n",
    "            else:\n",
    "                yield embeddings[batch_i], (targets[batch_i, 0], targets[batch_i, 1])\n",
    "            yielded += 1\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f2be6b-b765-49c3-baf3-cfb900f02f42",
   "metadata": {},
   "source": [
    "Naive implementation, flattened embeddings into FFN with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98313e89-cfa9-4bd9-bf5b-6f305ea0d7e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738218288.983263  101502 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21856 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738218298.552538  101651 service.cc:148] XLA service 0x7ff380003ff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1738218298.552553  101651 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2025-01-30 01:24:58.585521: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1738218298.664574  101651 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-01-30 01:24:59.581972: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "2025-01-30 01:24:59.620961: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 124 bytes spill stores, 124 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5/Unknown \u001b[1m10s\u001b[0m 39ms/step - end_loss: 10.5816 - end_sparse_categorical_accuracy: 0.0456 - loss: 24.2729 - start_loss: 13.6913 - start_sparse_categorical_accuracy: 0.2851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738218300.128642  101651 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    363/Unknown \u001b[1m52s\u001b[0m 116ms/step - end_loss: 3.9267 - end_sparse_categorical_accuracy: 0.3180 - loss: 6.9807 - start_loss: 3.0533 - start_sparse_categorical_accuracy: 0.5224  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:25:43.109154: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "2025-01-30 01:25:43.170376: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2025-01-30 01:25:43.209421: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-01-30 01:25:43.221181: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    365/Unknown \u001b[1m53s\u001b[0m 120ms/step - end_loss: 3.9196 - end_sparse_categorical_accuracy: 0.3186 - loss: 6.9683 - start_loss: 3.0480 - start_sparse_categorical_accuracy: 0.5225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:25:43.777815: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-01-30 01:25:43.777838: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2025-01-30 01:25:43.777855: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n",
      "/home/yu/kaggle-tweet-sentiment/.venv/lib64/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 147ms/step - end_loss: 3.9161 - end_sparse_categorical_accuracy: 0.3189 - loss: 6.9621 - start_loss: 3.0453 - start_sparse_categorical_accuracy: 0.5226 - val_end_loss: 1.9578 - val_end_sparse_categorical_accuracy: 0.5170 - val_loss: 3.6125 - val_start_loss: 1.6620 - val_start_sparse_categorical_accuracy: 0.5665\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:25:53.781832: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2025-01-30 01:25:53.781855: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:25:53.781860: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n",
      "2025-01-30 01:25:53.781868: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - end_loss: 1.6742 - end_sparse_categorical_accuracy: 0.5590 - loss: 3.1611 - start_loss: 1.4863 - start_sparse_categorical_accuracy: 0.5839 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:26:43.858907: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 141ms/step - end_loss: 1.6738 - end_sparse_categorical_accuracy: 0.5590 - loss: 3.1603 - start_loss: 1.4860 - start_sparse_categorical_accuracy: 0.5840 - val_end_loss: 1.8087 - val_end_sparse_categorical_accuracy: 0.5335 - val_loss: 3.3831 - val_start_loss: 1.5803 - val_start_sparse_categorical_accuracy: 0.5558\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:26:52.549803: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2025-01-30 01:26:52.549835: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:26:52.549855: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n",
      "2025-01-30 01:26:52.549863: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m361/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - end_loss: 1.3357 - end_sparse_categorical_accuracy: 0.6209 - loss: 2.6218 - start_loss: 1.2857 - start_sparse_categorical_accuracy: 0.6135 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:27:42.831833: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 142ms/step - end_loss: 1.3353 - end_sparse_categorical_accuracy: 0.6210 - loss: 2.6212 - start_loss: 1.2855 - start_sparse_categorical_accuracy: 0.6136 - val_end_loss: 1.9160 - val_end_sparse_categorical_accuracy: 0.5296 - val_loss: 3.5366 - val_start_loss: 1.6297 - val_start_sparse_categorical_accuracy: 0.5682\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:27:51.678702: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:27:51.678734: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n",
      "2025-01-30 01:27:51.678744: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 141ms/step - end_loss: 1.1291 - end_sparse_categorical_accuracy: 0.6659 - loss: 2.2797 - start_loss: 1.1502 - start_sparse_categorical_accuracy: 0.6457 - val_end_loss: 1.9340 - val_end_sparse_categorical_accuracy: 0.5199 - val_loss: 3.5473 - val_start_loss: 1.6229 - val_start_sparse_categorical_accuracy: 0.5706\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:28:50.340755: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2025-01-30 01:28:50.340786: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:28:50.340792: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n",
      "2025-01-30 01:28:50.340800: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - end_loss: 0.9226 - end_sparse_categorical_accuracy: 0.7157 - loss: 1.9350 - start_loss: 1.0120 - start_sparse_categorical_accuracy: 0.6862 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:29:40.381680: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:29:40.381705: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n",
      "2025-01-30 01:29:40.381717: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 141ms/step - end_loss: 0.9224 - end_sparse_categorical_accuracy: 0.7158 - loss: 1.9345 - start_loss: 1.0118 - start_sparse_categorical_accuracy: 0.6863 - val_end_loss: 2.1443 - val_end_sparse_categorical_accuracy: 0.5143 - val_loss: 3.8979 - val_start_loss: 1.7674 - val_start_sparse_categorical_accuracy: 0.5657\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:29:49.133353: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:29:49.133394: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m360/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - end_loss: 0.7712 - end_sparse_categorical_accuracy: 0.7558 - loss: 1.6593 - start_loss: 0.8877 - start_sparse_categorical_accuracy: 0.7176 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:30:39.476734: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:30:39.476764: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n",
      "2025-01-30 01:30:39.476774: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 142ms/step - end_loss: 0.7709 - end_sparse_categorical_accuracy: 0.7559 - loss: 1.6587 - start_loss: 0.8874 - start_sparse_categorical_accuracy: 0.7176 - val_end_loss: 2.1539 - val_end_sparse_categorical_accuracy: 0.5206 - val_loss: 3.9436 - val_start_loss: 1.8070 - val_start_sparse_categorical_accuracy: 0.5585\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:30:48.305963: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:30:48.305994: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n",
      "2025-01-30 01:30:48.306004: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m361/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - end_loss: 0.6340 - end_sparse_categorical_accuracy: 0.7985 - loss: 1.3963 - start_loss: 0.7619 - start_sparse_categorical_accuracy: 0.7524 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:31:38.415509: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:31:38.415535: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n",
      "2025-01-30 01:31:38.415544: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 142ms/step - end_loss: 0.6336 - end_sparse_categorical_accuracy: 0.7986 - loss: 1.3956 - start_loss: 0.7616 - start_sparse_categorical_accuracy: 0.7525 - val_end_loss: 2.3696 - val_end_sparse_categorical_accuracy: 0.5007 - val_loss: 4.1680 - val_start_loss: 1.8229 - val_start_sparse_categorical_accuracy: 0.5536\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:31:47.275073: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:31:47.275135: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n",
      "2025-01-30 01:31:47.275145: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m360/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - end_loss: 0.5322 - end_sparse_categorical_accuracy: 0.8252 - loss: 1.1813 - start_loss: 0.6487 - start_sparse_categorical_accuracy: 0.7881 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:32:37.475395: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:32:37.475421: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n",
      "2025-01-30 01:32:37.475431: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 141ms/step - end_loss: 0.5319 - end_sparse_categorical_accuracy: 0.8254 - loss: 1.1808 - start_loss: 0.6485 - start_sparse_categorical_accuracy: 0.7881 - val_end_loss: 2.4326 - val_end_sparse_categorical_accuracy: 0.5126 - val_loss: 4.3694 - val_start_loss: 1.9582 - val_start_sparse_categorical_accuracy: 0.5376\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:32:46.179293: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2025-01-30 01:32:46.179344: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:32:46.179350: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n",
      "2025-01-30 01:32:46.179358: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m364/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - end_loss: 0.4271 - end_sparse_categorical_accuracy: 0.8630 - loss: 0.9822 - start_loss: 0.5547 - start_sparse_categorical_accuracy: 0.8180 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:33:35.929406: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:33:35.929435: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n",
      "2025-01-30 01:33:35.929445: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 141ms/step - end_loss: 0.4270 - end_sparse_categorical_accuracy: 0.8630 - loss: 0.9821 - start_loss: 0.5547 - start_sparse_categorical_accuracy: 0.8180 - val_end_loss: 2.8005 - val_end_sparse_categorical_accuracy: 0.5017 - val_loss: 4.9659 - val_start_loss: 2.1900 - val_start_sparse_categorical_accuracy: 0.5687\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:33:44.689057: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:33:44.689120: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n",
      "2025-01-30 01:33:44.689129: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 140ms/step - end_loss: 0.3691 - end_sparse_categorical_accuracy: 0.8794 - loss: 0.8334 - start_loss: 0.4640 - start_sparse_categorical_accuracy: 0.8463 - val_end_loss: 2.9620 - val_end_sparse_categorical_accuracy: 0.5087 - val_loss: 5.2555 - val_start_loss: 2.3315 - val_start_sparse_categorical_accuracy: 0.5497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 01:34:43.031298: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 16646503622005204375\n",
      "2025-01-30 01:34:43.031330: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 8541295726000041299\n",
      "2025-01-30 01:34:43.031340: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 2868698929229645346\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(1 + max_text_len, 768))\n",
    "flat = layers.Flatten()(inputs)\n",
    "hidden = layers.Dense(256, activation=\"relu\", kernel_regularizer=\"l1l2\", bias_regularizer=\"l2\")(flat)\n",
    "softmax_start = layers.Dense(max_text_len, activation=\"softmax\", name=\"start\", kernel_regularizer=\"l1l2\", bias_regularizer=\"l2\")(hidden)\n",
    "softmax_end = layers.Dense(max_text_len, activation=\"softmax\", name=\"end\", kernel_regularizer=\"l1l2\", bias_regularizer=\"l2\")(hidden)\n",
    "ffn = keras.Model(inputs=inputs, outputs=(softmax_start, softmax_end))\n",
    "ffn.compile(\n",
    "    optimizer=optimizers.Adam(),\n",
    "    loss={\"start\": losses.SparseCategoricalCrossentropy(), \"end\": losses.SparseCategoricalCrossentropy()},\n",
    "    metrics={\"start\": metrics.SparseCategoricalAccuracy(), \"end\": metrics.SparseCategoricalAccuracy()}\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "encoder = TFAutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "dataset_train = tf.data.Dataset.from_generator(\n",
    "    dataset_generator(train.text.to_list(), train.sentiment.to_list(), train.selected_text.to_list()),\n",
    "    output_signature=(tf.TensorSpec(shape=(1 + max_text_len, 768)), (tf.TensorSpec(shape=()), tf.TensorSpec(shape=())))\n",
    ").shuffle(inference_batch_size)\n",
    "dataset_test = tf.data.Dataset.from_generator(\n",
    "    dataset_generator(test.text.to_list(), test.sentiment.to_list(), test.selected_text.to_list()),\n",
    "    output_signature=(tf.TensorSpec(shape=(1 + max_text_len, 768)), (tf.TensorSpec(shape=()), tf.TensorSpec(shape=())))\n",
    ")\n",
    "history = ffn.fit(dataset_train.batch(64), epochs=10, validation_data=dataset_test.batch(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc613c17-5308-43d2-9faf-6446fe5f3218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08917177226924795"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/competitions/tweet-sentiment-extraction\n",
    "def jaccard(str1, str2):\n",
    "    a = set(str1.lower().split())\n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "score = 0\n",
    "total = test.shape[0]\n",
    "(y_start, y_end) = ffn.predict(dataset_test.batch(64))\n",
    "y_start = tf.math.argmax(y_start, axis=1)\n",
    "y_end = tf.math.argmax(y_end, axis=1)\n",
    "for i in range(total):\n",
    "    span_start = y_start[i]\n",
    "    span_end = y_end[i]\n",
    "    y_str = test.text.iloc[i][span_start:span_end]\n",
    "    t_str = test.selected_text.iloc[i]\n",
    "    score += 1 / total * jaccard(y_str, t_str)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d9c44-5af9-4a6e-8f6c-e6470b605796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
